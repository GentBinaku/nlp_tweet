{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88aa8f3e-4a49-4fc7-9691-2d475fb1c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch import\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "549e1db5-95e7-4fd3-b922-d4b09a1995fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "447a98ba-3c7d-4516-beef-0b43552bc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561d201-0d8f-4bd7-b1df-950eacc5f589",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30230a60-4d90-4dc6-b202-156430274b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62cc99a3-de70-4d72-974d-6017a450d219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34124afb-74b8-4b77-ad6a-ca228c189ef1",
   "metadata": {},
   "source": [
    "### Remove unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a5b061e-0315-4049-972f-7b2dbd632207",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"keyword\",\"location\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "822b4b37-af2f-4710-b6f8-fa2f2694f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>10826</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>TN</td>\n",
       "      <td>On the bright side I wrecked http://t.co/uEa0t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#NewcastleuponTyne #UK</td>\n",
       "      <td>@widda16 ... He's gone. You can relax. I thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>London</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                       location  \\\n",
       "31       48   ablaze                     Birmingham   \n",
       "32       49   ablaze  Est. September 2012 - Bristol   \n",
       "33       50   ablaze                         AFRICA   \n",
       "34       52   ablaze               Philadelphia, PA   \n",
       "35       53   ablaze                     London, UK   \n",
       "...     ...      ...                            ...   \n",
       "7575  10826  wrecked                             TN   \n",
       "7577  10829  wrecked         #NewcastleuponTyne #UK   \n",
       "7579  10831  wrecked              Vancouver, Canada   \n",
       "7580  10832  wrecked                        London    \n",
       "7581  10833  wrecked                        Lincoln   \n",
       "\n",
       "                                                   text  target  \n",
       "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32    We always try to bring the heavy. #metal #RT h...       0  \n",
       "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                   Crying out for more! Set me ablaze       0  \n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
       "...                                                 ...     ...  \n",
       "7575  On the bright side I wrecked http://t.co/uEa0t...       0  \n",
       "7577  @widda16 ... He's gone. You can relax. I thoug...       0  \n",
       "7579  Three days off from work and they've pretty mu...       0  \n",
       "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "\n",
       "[5080 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908cfbe-c03d-4dc0-a040-f7a3c9e5e565",
   "metadata": {},
   "source": [
    "### Sample tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "70b947de-3c9a-4c2e-a6cd-5d7daea06b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  keyword                       location  \\\n",
      "32       49   ablaze  Est. September 2012 - Bristol   \n",
      "34       52   ablaze               Philadelphia, PA   \n",
      "35       53   ablaze                     London, UK   \n",
      "36       54   ablaze                       Pretoria   \n",
      "39       57   ablaze                 Paranaque City   \n",
      "...     ...      ...                            ...   \n",
      "7575  10826  wrecked                             TN   \n",
      "7577  10829  wrecked         #NewcastleuponTyne #UK   \n",
      "7579  10831  wrecked              Vancouver, Canada   \n",
      "7580  10832  wrecked                        London    \n",
      "7581  10833  wrecked                        Lincoln   \n",
      "\n",
      "                                                   text  target  \n",
      "32    We always try to bring the heavy. #metal #RT h...       0  \n",
      "34                   Crying out for more! Set me ablaze       0  \n",
      "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
      "36    @PhDSquares #mufc they've built so much hype a...       0  \n",
      "39                               Ablaze for you Lord :D       0  \n",
      "...                                                 ...     ...  \n",
      "7575  On the bright side I wrecked http://t.co/uEa0t...       0  \n",
      "7577  @widda16 ... He's gone. You can relax. I thoug...       0  \n",
      "7579  Three days off from work and they've pretty mu...       0  \n",
      "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
      "7581  @engineshed Great atmosphere at the British Li...       0  \n",
      "\n",
      "[2884 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df[train_df[\"target\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "848c1a99-27a9-4322-8c29-0313704c2b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id   keyword                   location  \\\n",
      "31       48    ablaze                 Birmingham   \n",
      "33       50    ablaze                     AFRICA   \n",
      "37       55    ablaze               World Wide!!   \n",
      "46       66    ablaze  GREENSBORO,NORTH CAROLINA   \n",
      "50       73    ablaze   Sheffield Township, Ohio   \n",
      "...     ...       ...                        ...   \n",
      "7541  10782  wreckage            New Delhi,India   \n",
      "7542  10783  wreckage               Xi'an, China   \n",
      "7543  10784  wreckage                     Mumbai   \n",
      "7552  10795   wrecked             Santa Cruz, CA   \n",
      "7572  10823   wrecked              Manhattan, NY   \n",
      "\n",
      "                                                   text  target  \n",
      "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
      "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
      "37    INEC Office in Abia Set Ablaze - http://t.co/3...       1  \n",
      "46    How the West was burned: Thousands of wildfire...       1  \n",
      "50    Deputies: Man shot before Brighton home set ab...       1  \n",
      "...                                                 ...     ...  \n",
      "7541  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n",
      "7542  Wreckage 'conclusively confirmed' as from miss...       1  \n",
      "7543  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n",
      "7552  Israel wrecked my home. Now it wants my land. ...       1  \n",
      "7572  @Kirafrog @mount_wario Did you get wrecked again?       1  \n",
      "\n",
      "[2196 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df[train_df[\"target\"] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbc5a7-fc5e-4e96-80ce-6fcd625ff30c",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e1e8a18-123f-4720-beb4-08d43706c735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(train_df['target'], bins=2, edgecolor='black')\n",
    "plt.title('Histogram of Target Variable')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1], ['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442425e-195a-4cbe-a494-75410bc0870e",
   "metadata": {},
   "source": [
    "### Plan of action"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77a5d90d-dfeb-4017-8ae6-4a77d95628ac",
   "metadata": {},
   "source": [
    "Vectorize the words but them through a datapipe or dataloader, define the model with LSTM layer and train it and see output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "79979582-d098-4dd9-af30-3ac75cad572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Class for constructing and managing a vocabulary for tweets text datasets.\"\"\"\n",
    "\n",
    "    def __init__(self, freq_threshold):\n",
    "        \"\"\"\n",
    "        Initialize the Vocabulary with a frequency threshold.\n",
    "\n",
    "        Args:\n",
    "            freq_threshold (int): A word's minimum frequency must be included in the vocabulary.\n",
    "        \"\"\"\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.idx2str = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.str2idx = {value: key for key, value in self.idx2str.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" Returns the size of the vocabulary.x`\"\"\"\n",
    "        return len(self.idx2str)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        \"\"\"\n",
    "        Tokenize the input text.\n",
    "\n",
    "        Args:\n",
    "            Text (str): The input text to tokenize.\n",
    "\n",
    "        Returns:\n",
    "            List: A list of tokenized and lowercase words.\n",
    "        \"\"\"\n",
    "        tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "        return [tok.lower() for tok in tokenizer.tokenize(text) if tok.strip()]\n",
    "    \n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        \"\"\"\n",
    "        Build the vocabulary dictionary from a list of sentences.\n",
    "\n",
    "        Args:\n",
    "            sentence_list (list of str): A list of sentences to build the vocabulary from.\n",
    "        \"\"\"\n",
    "        frequencies = Counter()\n",
    "        start_idx = len(self.idx2str)\n",
    "        \n",
    "        # Update word frequencies\n",
    "        for sentence in tqdm(sentence_list, desc=\"Building vocabulary\", total=len(sentence_list)):\n",
    "            frequencies.update(Counter(self.tokenizer_eng(sentence)))\n",
    "        \n",
    "        # Filter words based on frequency threshold\n",
    "        filtered_words = {word for word, count in frequencies.items() if count >= self.freq_threshold}\n",
    "        \n",
    "        # Add filtered words to vocabulary\n",
    "        self.str2idx.update({word: idx for idx, word in enumerate(filtered_words, start_idx)})\n",
    "        self.idx2str.update({idx: word for idx, word in enumerate(filtered_words, start_idx)})\n",
    "    \n",
    "    def numericalize(self, text):\n",
    "        \"\"\"\n",
    "        Convert text to a list of indices based on the vocabulary.\n",
    "\n",
    "        Args:\n",
    "            Text (str): The input text to convert.\n",
    "\n",
    "        Returns:\n",
    "            List: A list of indices corresponding to the words in the input text.\n",
    "        \"\"\"\n",
    "        tokens = self.tokenizer_eng(text)\n",
    "        return [self.str2idx.get(word, self.str2idx[\"<UNK>\"]) for word in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5b31d-38ee-4208-a5e2-e0e0a69797fd",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9a6c51a2-783a-4845-ab80-f2afb8f64e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetClassifierDataset(Dataset):\n",
    "    def __init__(self, df, text_vocab, keyword_vocab, location_vocab, num_words=100, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.num_words = num_words\n",
    "        self.text = df['text'].tolist()\n",
    "        self.keyword = df['keyword'].tolist()\n",
    "        self.location = df['location'].tolist()\n",
    "        self.ids = df['id'].tolist()  # Include IDs\n",
    "        self.transform = transform\n",
    "        self.text_vocab = text_vocab\n",
    "        self.keyword_vocab = keyword_vocab\n",
    "        self.location_vocab = location_vocab\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # Build vocabularies from the dataset if needed\n",
    "        self.text_vocab.build_vocabulary(self.text)\n",
    "        self.keyword_vocab.build_vocabulary(self.keyword)\n",
    "        self.location_vocab.build_vocabulary(self.location)\n",
    "        \n",
    "        if not is_test:\n",
    "            self.target = df['target'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.text[idx]\n",
    "        keyword = self.keyword[idx]\n",
    "        location = self.location[idx]\n",
    "        id_ = self.ids[idx]  # Get the ID\n",
    "        \n",
    "        if not self.is_test:\n",
    "            target = self.target[idx]\n",
    "            target = torch.tensor(target)\n",
    "        else:\n",
    "            target = torch.tensor(-1)  # Placeholder for test data, not used in inference\n",
    "        \n",
    "        if self.transform:\n",
    "            tweet = self.transform(tweet)\n",
    "       \n",
    "        text_numericalized = self.text_vocab.numericalize(tweet)\n",
    "        keyword_numericalized = self.keyword_vocab.numericalize(keyword)\n",
    "        location_numericalized = self.location_vocab.numericalize(location)\n",
    "        \n",
    "        # Padding or truncating\n",
    "        if len(text_numericalized) < self.num_words:\n",
    "            text_numericalized.extend([self.text_vocab.str2idx[\"<PAD>\"]] * (self.num_words - len(text_numericalized)))\n",
    "        else:\n",
    "            text_numericalized = text_numericalized[:self.num_words]\n",
    "        \n",
    "        text_numericalized = torch.tensor(text_numericalized)\n",
    "        keyword_numericalized = torch.tensor(keyword_numericalized)\n",
    "        location_numericalized = torch.tensor(location_numericalized)\n",
    "\n",
    "        return {\n",
    "            'id': id_,  # Include ID in the return\n",
    "            'text': text_numericalized,\n",
    "            'keyword': keyword_numericalized,\n",
    "            'location': location_numericalized,\n",
    "            'target': target  # Optional for test\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13bebda-bf14-48a4-b746-da57cb5a571e",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3ad9f-2370-4ef5-8763-eec08393a274",
   "metadata": {},
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef8d6a-5a66-4475-b310-623982bcd043",
   "metadata": {},
   "source": [
    "Using a Bi-LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89e994cf-2375-454a-a3dc-bc30e82ac969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TweetClassifier(nn.Module):\n",
    "    def __init__(self, output_size, vocab_size, embedding_dim, hidden_dim, num_layers, kernels, num_filters, keyword_vocab_size, location_vocab_size):\n",
    "        super(TweetClassifier, self).__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.text_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.keyword_embedding = nn.Embedding(keyword_vocab_size, embedding_dim)\n",
    "        self.location_embedding = nn.Embedding(location_vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer for LSTM output\n",
    "        self.lstm_fc = nn.Linear(hidden_dim, hidden_dim)  # Ensure this matches the hidden_dim\n",
    "        \n",
    "        # CNN layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (K, embedding_dim)) for K in kernels\n",
    "        ])\n",
    "        \n",
    "        # Calculate the total number of features after concatenation\n",
    "        total_features = hidden_dim + len(kernels) * num_filters\n",
    "        \n",
    "        # Fully connected layer for combined output\n",
    "        self.fc = nn.Linear(total_features, output_size)\n",
    "        \n",
    "    def forward(self, text, keyword, location):\n",
    "        # Embedding lookups\n",
    "        text_embeds = self.text_embedding(text)\n",
    "        keyword_embeds = self.keyword_embedding(keyword)\n",
    "        location_embeds = self.location_embedding(location)\n",
    "        \n",
    "        # LSTM Processing\n",
    "        lstm_input = text_embeds\n",
    "        lstm_out, (hn, _) = self.lstm(lstm_input)\n",
    "        lstm_out = self.lstm_fc(hn[-1])  # Use the last hidden state\n",
    "        \n",
    "        # CNN Processing\n",
    "        combined_embeds = torch.cat([text_embeds, keyword_embeds, location_embeds], dim=1)\n",
    "        combined_embeds = combined_embeds.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        conv_outs = [torch.relu(conv(combined_embeds)).squeeze(3) for conv in self.convs]\n",
    "        pooled_outs = [torch.max(out, dim=2)[0] for out in conv_outs]\n",
    "        \n",
    "        # Concatenate LSTM output and CNN outputs\n",
    "        combined_out = torch.cat([lstm_out] + pooled_outs, dim=1)\n",
    "        \n",
    "        # Final fully connected layer\n",
    "        out = self.fc(combined_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa86a2f-b60b-4482-aeba-d573601dec84",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8407578-a9d2-4bea-9ff2-e23455bdf649",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "86f0a044-69ff-4087-85b4-d9fe9becf11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building vocabulary:   0%|                                                                                                                                         | 0/4064 [00:00<?, ?it/s]\u001b[A\n",
      "Building vocabulary:  39%|███████████████████████████████████████████████▉                                                                           | 1583/4064 [00:00<00:00, 15827.83it/s]\u001b[A\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4064/4064 [00:00<00:00, 15524.98it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4064/4064 [00:00<00:00, 67167.83it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4064/4064 [00:00<00:00, 48653.35it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1016/1016 [00:00<00:00, 13817.23it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1016/1016 [00:00<00:00, 66175.12it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1016/1016 [00:00<00:00, 50835.80it/s]\u001b[A\n",
      "[train] 1/5: 100%|\u001b[32m###############################################################################################\u001b[0m| 8/8 [02:03<00:00, 15.50s/it, avg_train_acc=0.5668, avg_train_loss=0.7286]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Epoch 1/5 - Loss: 0.7187, Accuracy: 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train] 2/5: 100%|\u001b[32m###############################################################################################\u001b[0m| 8/8 [02:00<00:00, 15.12s/it, avg_train_acc=0.5667, avg_train_loss=0.7167]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Epoch 2/5 - Loss: 0.7177, Accuracy: 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train] 3/5: 100%|\u001b[32m###############################################################################################\u001b[0m| 8/8 [02:06<00:00, 15.76s/it, avg_train_acc=0.5670, avg_train_loss=0.7165]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Epoch 3/5 - Loss: 0.7176, Accuracy: 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train] 4/5: 100%|\u001b[32m###############################################################################################\u001b[0m| 8/8 [02:08<00:00, 16.01s/it, avg_train_acc=0.5668, avg_train_loss=0.7164]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Epoch 4/5 - Loss: 0.7176, Accuracy: 0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train] 5/5: 100%|\u001b[32m###############################################################################################\u001b[0m| 8/8 [02:24<00:00, 18.11s/it, avg_train_acc=0.5668, avg_train_loss=0.7164]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] Epoch 5/5 - Loss: 0.7176, Accuracy: 0.5707\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# General Params\n",
    "add_lr_scheduler = True\n",
    "output_size = 1\n",
    "batch_size = 512\n",
    "n_epochs = 5\n",
    "\n",
    "# Embedding params\n",
    "num_words = 100\n",
    "vocab_size = 7581\n",
    "embedding_dim = 728\n",
    "\n",
    "# CNN Params\n",
    "kernels = (2, 3, 4, 5)\n",
    "num_filters = 8  # 8 ==> 16\n",
    "\n",
    "# LSTM Params\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "\n",
    "# Load data\n",
    "data_df = pd.read_csv(train_path)\n",
    "data_df.dropna(subset=[\"keyword\",\"location\"], inplace=True)\n",
    "\n",
    "# Assuming your DataFrame has 'text', 'target', 'keyword', and 'location' columns\n",
    "X = data_df[['id', 'text', 'keyword', 'location']]  # Features (tweets, keywords, locations)\n",
    "y = data_df['target']  # Labels (targets)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine the features and target back into DataFrames\n",
    "train_df = pd.concat([x_train, y_train], axis=1)\n",
    "valid_df = pd.concat([x_valid, y_valid], axis=1)\n",
    "\n",
    "# Initialize vocabularies for text, keyword, and location\n",
    "text_vocab = Vocabulary(freq_threshold=5)\n",
    "keyword_vocab = Vocabulary(freq_threshold=5)\n",
    "location_vocab = Vocabulary(freq_threshold=5)\n",
    "\n",
    "# Define any transform if required (can be None)\n",
    "transform = None\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch, text_vocab, keyword_vocab, location_vocab, num_words):\n",
    "    # Extract features and targets\n",
    "    ids = [item['id'] for item in batch]\n",
    "    texts = [item['text'] for item in batch]\n",
    "    keywords = [item['keyword'] for item in batch]\n",
    "    locations = [item['location'] for item in batch]\n",
    "\n",
    "    # Pad sequences to max length in the batch\n",
    "    max_text_len = num_words  # Assuming fixed length padding/truncating for text\n",
    "    text_padded = torch.full((len(texts), max_text_len), fill_value=text_vocab.str2idx[\"<PAD>\"], dtype=torch.long)\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        text_len = len(text)\n",
    "        if text_len > max_text_len:\n",
    "            text_len = max_text_len\n",
    "        text_padded[i, :text_len] = text[:text_len]\n",
    "\n",
    "    # Assuming keyword and location tensors are of the same length\n",
    "    max_keyword_len = max(len(keyword) for keyword in keywords)\n",
    "    max_location_len = max(len(location) for location in locations)\n",
    "    \n",
    "    keyword_padded = torch.full((len(keywords), max_keyword_len), fill_value=keyword_vocab.str2idx[\"<PAD>\"], dtype=torch.long)\n",
    "    location_padded = torch.full((len(locations), max_location_len), fill_value=location_vocab.str2idx[\"<PAD>\"], dtype=torch.long)\n",
    "\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        keyword_len = len(keyword)\n",
    "        if keyword_len > max_keyword_len:\n",
    "            keyword_len = max_keyword_len\n",
    "        keyword_padded[i, :keyword_len] = keyword[:keyword_len]\n",
    "\n",
    "    for i, location in enumerate(locations):\n",
    "        location_len = len(location)\n",
    "        if location_len > max_location_len:\n",
    "            location_len = max_location_len\n",
    "        location_padded[i, :location_len] = location[:location_len]\n",
    "\n",
    "    # Handle targets if they exist\n",
    "    targets = None\n",
    "    if 'target' in batch[0]:\n",
    "        targets = torch.tensor([item['target'] for item in batch], dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        'id': ids,\n",
    "        'text': text_padded,\n",
    "        'keyword': keyword_padded,\n",
    "        'location': location_padded,\n",
    "        'target': targets\n",
    "    }\n",
    "# Create the dataset for training\n",
    "train_dataset = TweetClassifierDataset(\n",
    "    df=train_df, \n",
    "    text_vocab=text_vocab, \n",
    "    keyword_vocab=keyword_vocab, \n",
    "    location_vocab=location_vocab, \n",
    "    num_words=num_words, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create the dataset for validation\n",
    "valid_dataset = TweetClassifierDataset(\n",
    "    df=valid_df, \n",
    "    text_vocab=text_vocab, \n",
    "    keyword_vocab=keyword_vocab, \n",
    "    location_vocab=location_vocab, \n",
    "    num_words=num_words, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(batch, text_vocab=text_vocab, keyword_vocab=keyword_vocab, location_vocab=location_vocab, num_words=num_words)\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: collate_fn(batch, text_vocab=text_vocab, keyword_vocab=keyword_vocab, location_vocab=location_vocab, num_words=num_words)\n",
    ")\n",
    "\n",
    "# Model\n",
    "# Model\n",
    "model = TweetClassifier(\n",
    "    output_size=output_size,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    kernels=kernels,\n",
    "    num_filters=num_filters,\n",
    "    keyword_vocab_size=len(keyword_vocab),\n",
    "    location_vocab_size=len(location_vocab)\n",
    ").to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()  # Assuming binary classification\n",
    "\n",
    "# Optional: Learning rate scheduler\n",
    "if add_lr_scheduler:\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Example scheduler\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_running_loss = 0\n",
    "    train_running_acc = 0\n",
    "    \n",
    "    tqdm_train_iterator = tqdm(enumerate(train_loader),\n",
    "                               desc=f\"[train] {epoch+1}/{n_epochs}\",\n",
    "                               ascii=True, leave=True,\n",
    "                               total=len(train_loader),\n",
    "                               colour=\"green\", position=0)\n",
    "    \n",
    "    for batch_idx, batch in tqdm_train_iterator:\n",
    "        text = batch['text'].to(device)\n",
    "        keyword = batch['keyword'].to(device)\n",
    "        location = batch['location'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(text, keyword, location)  # Pass all features to the model\n",
    "        \n",
    "        # Assuming binary classification with logits; apply sigmoid if needed\n",
    "        if output_size == 1:\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "        # Ensure target is of type Float\n",
    "        target = target.unsqueeze(1).float()  # Shape: [batch_size, 1]\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(y_pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        if add_lr_scheduler:\n",
    "            scheduler.step()  # Step the scheduler if used\n",
    "        \n",
    "        # Compute accuracy\n",
    "        if output_size == 1:\n",
    "            train_running_acc += ((y_pred > 0.5).float() == target).sum().item() / target.size(0)\n",
    "        else:\n",
    "            # For multi-class, use the correct accuracy computation\n",
    "            train_running_acc += get_accuracy_without_softmax(y_pred.detach(), target)\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        tqdm_train_iterator.set_postfix(\n",
    "            avg_train_acc=f\"{train_running_acc / (batch_idx + 1):0.4f}\",\n",
    "            avg_train_loss=f\"{train_running_loss / (batch_idx + 1):0.4f}\"\n",
    "        )\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    valid_running_loss = 0\n",
    "    valid_running_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            text = batch['text'].to(device)\n",
    "            keyword = batch['keyword'].to(device)\n",
    "            location = batch['location'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "            \n",
    "            y_pred = model(text, keyword, location)\n",
    "            \n",
    "            if output_size == 1:\n",
    "                y_pred = torch.sigmoid(y_pred)\n",
    "            \n",
    "            target = target.unsqueeze(1).float()  # Shape: [batch_size, 1]\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(y_pred, target)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            if output_size == 1:\n",
    "                valid_running_acc += ((y_pred > 0.5).float() == target).sum().item() / target.size(0)\n",
    "            else:\n",
    "                valid_running_acc += get_accuracy_without_softmax(y_pred.detach(), target)\n",
    "            \n",
    "            valid_running_loss += loss.item()\n",
    "    \n",
    "    print(f\"[Validation] Epoch {epoch+1}/{n_epochs} - Loss: {valid_running_loss / len(valid_loader):.4f}, Accuracy: {valid_running_acc / len(valid_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d505051a-816e-45eb-b093-e92bccaee594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test data\n",
    "test_df = pd.read_csv(test_path)\n",
    "test_df.dropna(subset=[\"keyword\",\"location\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c016550-17ce-4c2a-962d-157636577b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Niall's place | SAF 12 SQUAD |</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NIGERIA</td>\n",
       "      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Los Angeles, Califnordia</td>\n",
       "      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>10804</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Love Reiss</td>\n",
       "      <td>@yakubOObs think he deactivated because his no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>10806</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Seattle Washington</td>\n",
       "      <td>RT CNBC '3 words from Disney CEO Bob Iger wrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>10807</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Acey mountain islanddåÇTorontoåÈ</td>\n",
       "      <td>Smackdown tyme this should put me in a good mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>10816</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>@thrillhho jsyk I haven't stopped thinking abt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>10820</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>@stighefootball Begovic has been garbage. He g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2158 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                          location  \\\n",
       "15       46   ablaze                            London   \n",
       "16       47   ablaze    Niall's place | SAF 12 SQUAD |   \n",
       "17       51   ablaze                           NIGERIA   \n",
       "18       58   ablaze                    Live On Webcam   \n",
       "19       60   ablaze          Los Angeles, Califnordia   \n",
       "...     ...      ...                               ...   \n",
       "3246  10804  wrecked                        Love Reiss   \n",
       "3247  10806  wrecked                Seattle Washington   \n",
       "3248  10807  wrecked  Acey mountain islanddåÇTorontoåÈ   \n",
       "3249  10816  wrecked                       los angeles   \n",
       "3250  10820  wrecked                 Brussels, Belgium   \n",
       "\n",
       "                                                   text  \n",
       "15    Birmingham Wholesale Market is ablaze BBC News...  \n",
       "16    @sunkxssedharry will you wear shorts for race ...  \n",
       "17    #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...  \n",
       "18    Check these out: http://t.co/rOI2NSmEJJ http:/...  \n",
       "19    PSA: IÛªm splitting my personalities.\\n\\n?? t...  \n",
       "...                                                 ...  \n",
       "3246  @yakubOObs think he deactivated because his no...  \n",
       "3247  RT CNBC '3 words from Disney CEO Bob Iger wrec...  \n",
       "3248  Smackdown tyme this should put me in a good mo...  \n",
       "3249  @thrillhho jsyk I haven't stopped thinking abt...  \n",
       "3250  @stighefootball Begovic has been garbage. He g...  \n",
       "\n",
       "[2158 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "202cce07-08ee-4dcb-8800-312f965b46f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building vocabulary:   0%|                                                                                                                                         | 0/2158 [00:00<?, ?it/s]\u001b[A\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2158/2158 [00:00<00:00, 13071.16it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2158/2158 [00:00<00:00, 74781.95it/s]\u001b[A\n",
      "\n",
      "Building vocabulary: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2158/2158 [00:00<00:00, 51344.74it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_BAD_PARAM_STREAM_MISMATCH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 25\u001b[0m\n\u001b[1;32m     17\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     18\u001b[0m     test_dataset,\n\u001b[1;32m     19\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     20\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m batch: collate_fn(batch, text_vocab\u001b[38;5;241m=\u001b[39mtext_vocab, keyword_vocab\u001b[38;5;241m=\u001b[39mkeyword_vocab, location_vocab\u001b[38;5;241m=\u001b[39mlocation_vocab, num_words\u001b[38;5;241m=\u001b[39mnum_words)\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Ensure the model is in evaluation mode\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Initialize lists to store results\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/nlp_tweet/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/nlp_tweet/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/nlp_tweet/lib/python3.11/site-packages/torch/nn/modules/rnn.py:228\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    223\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_apply(fn, recurse)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_flat_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.pyenv/versions/nlp_tweet/lib/python3.11/site-packages/torch/nn/modules/rnn.py:163\u001b[0m, in \u001b[0;36mRNNBase._init_flat_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    160\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    162\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/nlp_tweet/lib/python3.11/site-packages/torch/nn/modules/rnn.py:215\u001b[0m, in \u001b[0;36mRNNBase.flatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    214\u001b[0m     num_weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 215\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cudnn_rnn_flatten_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cudnn_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_BAD_PARAM_STREAM_MISMATCH"
     ]
    }
   ],
   "source": [
    "# Initialize vocabularies for text, keyword, and location\n",
    "text_vocab = Vocabulary(freq_threshold=1)\n",
    "keyword_vocab = Vocabulary(freq_threshold=1)\n",
    "location_vocab = Vocabulary(freq_threshold=1)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = TweetClassifierDataset(\n",
    "    df=test_df,\n",
    "    text_vocab=text_vocab,\n",
    "    keyword_vocab=keyword_vocab,\n",
    "    location_vocab=location_vocab,\n",
    "    num_words=num_words,\n",
    "    transform=transform,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: collate_fn(batch, text_vocab=text_vocab, keyword_vocab=keyword_vocab, location_vocab=location_vocab, num_words=num_words)\n",
    ")\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        ids = batch['id']\n",
    "        text = batch['text'].to(device)\n",
    "        keyword = batch['keyword'].to(device)\n",
    "        location = batch['location'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(text, keyword, location)\n",
    "\n",
    "        # Assuming binary classification with logits; apply sigmoid if needed\n",
    "        if output_size == 1:\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convert outputs to numpy and collect results\n",
    "        predictions = outputs.cpu().numpy()\n",
    "        # Collect results with IDs\n",
    "        for id_, prediction in zip(ids, predictions):\n",
    "            results.append({'id': id_, 'target': prediction[0]})  # Flatten prediction if necessary\n",
    "\n",
    "# Create a DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc80354-8d18-4846-b77c-2d271e7b97aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
